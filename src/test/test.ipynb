{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfc85b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Function to preprocess mixed audio\n",
    "def preprocess_audio(audio_path, duration, sr):\n",
    "    audio, _ = librosa.load(audio_path, sr=sr, duration=duration)\n",
    "    if len(audio) < duration * sr:\n",
    "        # If the audio is shorter than the expected duration, pad it with zeros\n",
    "        audio = np.pad(audio, (0, duration * sr - len(audio)))\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio\n",
    "\n",
    "# Function to predict the separated sources\n",
    "def predict_separation(model, mixed_audio):\n",
    "    mixed_audio = mixed_audio[np.newaxis, ...]  # Add batch dimension\n",
    "    predicted_sources = model.predict(mixed_audio)\n",
    "    return predicted_sources[0]  # Remove batch dimension\n",
    "\n",
    "# Function to save the separated sources\n",
    "def save_audio(output_dir, sources, sr):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    instrument_names = ['fiddle', 'flute', 'xylophone']\n",
    "    for i, instrument in enumerate(instrument_names):\n",
    "        output_path = os.path.join(output_dir, f'{instrument}.mp3')\n",
    "        sf.write(output_path, sources[:, i], sr)\n",
    "\n",
    "# Function to separate audio using the trained model\n",
    "def separate_audio(model, input_audio_path, output_dir, duration, sr):\n",
    "    # Load and preprocess the mixed audio\n",
    "    mixed_audio = preprocess_audio(input_audio_path, duration, sr)\n",
    "\n",
    "    # Predict the separated sources\n",
    "    separated_sources = predict_separation(model, mixed_audio)\n",
    "\n",
    "    # Save the separated sources\n",
    "    save_audio(output_dir, separated_sources, sr)\n",
    "\n",
    "# Example usage\n",
    "input_audio_path = '/content/Mix_เพลงเทส_Stereo.mp3'  # Path to your mixed audio file\n",
    "output_dir = '/content/separated_audio'  # Directory where you want to save the separated tracks\n",
    "duration = 30  # seconds\n",
    "sr = 44100  # sample rate\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(model.h5)\n",
    "\n",
    "# Separate the audio and save the output\n",
    "separate_audio(model, input_audio_path, output_dir, duration, sr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
